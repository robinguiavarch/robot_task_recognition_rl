{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 1 â€” Event-to-Action Recognition (OpenTheChests)\n",
    "\n",
    "##### **Authors**: FranÃ§ois-Xavier Morel - Mathieu Delarue - Laury Magne - Robin Guiavarch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Summary**\n",
    "\n",
    "Welcome to the notebook dedicated to **Agent 1: Event-to-Action Recognition** using the *OpenTheChests* environment.  \n",
    "This notebook explores three progressively complex approaches to mapping event sequences to actions using reinforcement learning.\n",
    "\n",
    "\n",
    "#### ðŸ“š **Table of Contents**\n",
    "\n",
    "ðŸ”¹ **1. Simple Approach: One-to-One Event Mapping**\n",
    "- [1.1. Event Visualization](#11-event-visualization)\n",
    "- [1.2. Model Training](#12-model-training)\n",
    "  - [1.2.1. PPO](#121-ppo)\n",
    "  - [1.2.2. DQN](#122-dqn)\n",
    "- [1.3. Learning Curves](#13-learning-curves)\n",
    "  - [1.3.1. PPO](#131-ppo)\n",
    "  - [1.3.2. DQN](#132-dqn)\n",
    "- [1.4. Model Evaluation](#14-model-evaluation)\n",
    "  - [1.4.1. PPO](#141-ppo)\n",
    "  - [1.4.2. DQN](#142-dqn)\n",
    "\n",
    "ðŸ”¹ **2. Intermediate Approach: Temporal Window**\n",
    "- [2.1. Event Visualization](#21-event-visualization)\n",
    "- [2.2. Model Training](#22-model-training)\n",
    "- [2.3. Learning Curves](#23-learning-curves)\n",
    "- [2.4. Model Evaluation](#24-model-evaluation)\n",
    "\n",
    "\n",
    "ðŸ”¹ **3. Advanced Approach: Sequence Modeling**\n",
    "- [3.1. Event Visualization](#31-event-visualization)\n",
    "- [3.2. Model Training](#32-model-training)\n",
    "- [3.3. Learning Curves](#33-learning-curves)\n",
    "- [3.4. Model Evaluation](#34-model-evaluation)\n",
    "\n",
    "#### ðŸ§¾ Project Overview\n",
    "\n",
    "This notebook is part of the project **\"Reinforcement Learning for Robotic Task Recognition in Event-Driven Environments\"**.  \n",
    "It focuses on **Agent 1**, whose goal is to learn how to recognize meaningful patterns in a stream of symbolic events and decide which chest to open in the environment called **OpenTheChests**.\n",
    "\n",
    "#### ðŸŽ¯ Objective\n",
    "\n",
    "Agent 1 must learn to:\n",
    "- Observe a continuous stream of symbolic events (e.g., A, B, C...)\n",
    "- Recognize valid event patterns (with or without noise)\n",
    "- Map those patterns to the correct action (i.e., open the right chest)\n",
    "\n",
    "The agent is trained using **Reinforcement Learning (RL)**, with several architectures and levels of complexity explored in this notebook:\n",
    "1. **Simple Mapping** (Single event â†’ Action)\n",
    "2. **Temporal Window** (Short sequences of events)\n",
    "3. **Advanced Sequence Modeling** (LSTM, Transformer)\n",
    "\n",
    "#### ðŸ§ª Environments & Tools\n",
    "\n",
    "The experiments rely on:\n",
    "- Custom Gym environments (`OpenTheChests-v0`, `v1`, `v2`)\n",
    "- Event visualization with Matplotlib\n",
    "- Training configuration through `.yaml` files\n",
    "- Evaluation metrics: **average reward**, **success rate**, **learning curves**\n",
    "\n",
    "\n",
    "ðŸ“Œ Follow the notebook sections in order to visualize events, train, and evaluate the models step by step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Patch for numpy.bool8 removal in NumPy >= 1.24\n",
    "import numpy as np\n",
    "if not hasattr(np, \"bool8\"):\n",
    "    np.bool8 = np.bool_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Approach: One-to-One Event Mapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1. Event Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PROJECT_ROOT added to PYTHONPATH: /robinguiavarch/Documents/git_projects/robot_task_recognition_rl\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Assurez-vous que le rÃ©pertoire racine de votre projet est correct.\n",
    "PROJECT_ROOT = \"/robinguiavarch/Documents/git_projects/robot_task_recognition_rl\"\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(\"âœ… PROJECT_ROOT added to PYTHONPATH:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'agent1_patterns_chests_to_reach'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magent1_patterns_chests_to_reach\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_collectors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collect_observations\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magent1_patterns_chests_to_reach\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menv\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregister_envs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_custom_envs\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magent1_patterns_chests_to_reach\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_event_timeline\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'agent1_patterns_chests_to_reach'"
     ]
    }
   ],
   "source": [
    "from agent1_patterns_chests_to_reach.utils.data_collectors import collect_observations\n",
    "from agent1_patterns_chests_to_reach.env.register_envs import register_custom_envs\n",
    "from agent1_patterns_chests_to_reach.utils.visualization import plot_event_timeline\n",
    "\n",
    "# Register environments\n",
    "register_custom_envs()\n",
    "\n",
    "# Collect and visualize events\n",
    "observed_events_easy = collect_observations(\"OpenTheChests-v0\", num_steps=10)\n",
    "plot_event_timeline(observed_events_easy, start_time=0, end_time=observed_events_easy[-1][\"end_time\"], env_name=\"OpenTheChests-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Model Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. PPO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. DQN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Learning Curves\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1. PPO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2. DQN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Model Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1. PPO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2. DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Intermediate Approach: Temporal Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Event Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Approach: Sequence Modeling (LSTM / Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Event Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot-task-recognition-rl-5EzxE_ra-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
